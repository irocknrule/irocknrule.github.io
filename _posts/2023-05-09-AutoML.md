# Using AutoGluon on Tabular datasets

## Why use AutoGluon?

AutoGluon is an open source package within the class of AutoML techniques to make machine learning easier and more accessible. The description of AutoGluon is stated as (from [1]):

AutoGluon enables easy-to-use and easy-to-extend AutoML with a focus on automated stack ensembling, deep learning, and real-world applications spanning image, text, and tabular data. Intended for both ML beginners and experts, 

AutoGluon enables you to:

- Quickly prototype deep learning and classical ML solutions for your raw data with a few lines of code.
- Automatically utilize state-of-the-art techniques (where appropriate) without expert knowledge.
- Leverage automatic hyperparameter tuning, model selection/ensembling, architecture search, and data processing.
- Easily improve/tune your bespoke models and data pipelines, or customize AutoGluon for your use-case.

I was interested to try to use this on a real world example to explore the possibilities and learn more about model building using this tool. Online research indicated that it is particularly useful for modeling tabular datasets out of the box, so I selected the American Express — Default Prediction Kaggle competition. The advantages of using a Kaggle dataset are:

- Datasets are public, so there are no worries regarding disclosing work-related confidential information.
- The Kaggle community is large and numerous people publish their modeling techniques. While some folks are serious about winning, most people use it to learn various modeling approaches and use their results to compare against the state-of-the-art.
- The public and private leaderboards provide a ready ability to evaluate the designed models.

Using AutoGluon to come up with a starting model for this competition provides an opportunity to come up with a baseline model with minimal starting effort. Once we have a baseline model, then we could work more on fine-tuning, hyper parameter optimization , feature engineering and other architectural improvements to improve the overall accuracy.

## Data set and goals

The official input datasets for the Kaggle Amex competition are provided are provided here. Due to the large size of the dataset, folks in the community converted the input CSVs into a smaller parquet format which was widely used. For this analysis, I have re-used this dataset which was shared publicly at this location [2]. The competition also provided a specific evaluation metric as defined here, however for simplicity and again ease of use with the goal of evaluation AutoGluon, I used the standard ‘recall’ metric to compute model scores.

## Autogluon modeling

I used a Sagemaker ml.g4dn.4xlarge instance which has enough memory and a GPU to enable faster model training. By specifying the ag_args_fit={‘num_gpus’: 1} parameter to fit, we can specify usage of the GPU instead of the CPU whenever possible.

After installing AutoGluon locally, you simply import the Tabular libraries directly:

```from autogluon.tabular import TabularDataset, TabularPredictor```

After reading the training data (using the parquet files) we convert some of the pre-specified columns to categorical variables explicitly and then invoke AutoGluon fitting.

A quick note here, AutoGluon enables fast prototyping and modeling with smaller training datasets, time limits and little hyper-parameter tuning to ensure we can get some working code up and running. After some experimentation with smaller subsample sizes and letting AutoGluon fit all 13+ models, I observed that some models work better than others and ensembling them according to AutoGluon’s layered stacking strategies gives us good results. I landed upon using the following modeling techniques, which can then be passed in as a dict to the *fit* function.

```
hyperparams = { # hyperparameters of each model type
              ‘GBM’: {}, # Gradient-Boosting Trees
              ‘XGB’: {}, # XGBoost
              ‘FASTAI’: {}, # Neural nets from FastIA
              ‘CAT’: {}, # CatBoost
              ‘NN_TORCH’: {} # Neural nets from PyTorch
 }
```

Note that I have not specified individual hyper-parameters for every model, which can be included as well. This is because in the call to the fit function, I specify that we want the ‘best quality’, so AutoGluon automatically selects the best set of hyper parameters to search. Since my goal is to measure how AutoGluon performs right out the gate, without any specific feature engineering or optimizations, I kept the default options. Here is the call to the *fit* method:

```
predictor = TabularPredictor(label='target',
                             eval_metric='recall',)
                             .fit(train_df,ag_args_fit={'num_gpus': 1}
                             ,hyperparameters=hyperparams
                             ,time_limit=4*60*60,presets=["best_quality"])
```

AutoGluon then starts the training process, which we have specified to have an time limit of 4 hours, use the GPU when possible and use recall as our evaluation metric. 

Some sample output from the process indicates how AutoGluon starts working here:

```
No path specified. Models will be saved in: "AutogluonModels/ag-20220924_172812/"
Presets specified: ['best_quality']
Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=20
Beginning AutoGluon training ... Time limit = 14400s
AutoGluon will save models to "AutogluonModels/ag-20220924_172812/"
AutoGluon Version:  0.5.2
Python Version:     3.8.12
Operating System:   Linux
Train Data Rows:    458913
Train Data Columns: 189
Label Column: target
Preprocessing data ...
AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).
	2 unique label values:  [0, 1]
	If 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])
Selected class <--> label mapping:  class 1 = 1, class 0 = 0
Using Feature Generators to preprocess the data ...
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    34811.0 MB
	Train Data (Original)  Memory Usage: 827.85 MB (2.4% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting CategoryFeatureGenerator...
			Fitting CategoryMemoryMinimizeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Unused Original Features (Count: 1): ['customer_ID']
		These features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.
		Features can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.
		These features do not need to be present at inference time.
		('object', []) : 1 | ['customer_ID']
	Types of features in original data (raw dtype, special dtypes):
		('float', [])  : 177 | ['P_2', 'D_39', 'B_1', 'B_2', 'R_1', ...]
		('object', []) :  11 | ['D_63', 'D_64', 'D_66', 'D_68', 'B_30', ...]
	Types of features in processed data (raw dtype, special dtypes):
		('category', []) :  11 | ['D_63', 'D_64', 'D_66', 'D_68', 'B_30', ...]
		('float', [])    : 177 | ['P_2', 'D_39', 'B_1', 'B_2', 'R_1', ...]
	11.9s = Fit runtime
	188 features in original data used to generate 188 features in processed data.
	Train Data (Processed) Memory Usage: 484.16 MB (1.4% of available memory)
Data preprocessing and feature engineering runtime = 13.68s ...
AutoGluon will gauge predictive performance using evaluation metric: 'recall'
	To change this, specify the eval_metric parameter of Predictor()
Fitting 5 L1 models ...
Fitting model: LightGBM_BAG_L1 ... Training model for up to 14386.32s of the 14386.31s of remaining time.
```
